{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorem = sc.textFile('lorem.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, False, False, False, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lorem.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorem_sl = lorem.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lorem_sl.useDisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lorem_sl.useMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lorem_sl.useOffHeap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lorem_sl.deserialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lorem_sl.replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33505"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Caching\n",
    "doc = sc.textFile(\"shakespeare.txt\")\n",
    "\n",
    "words = doc.flatMap(lambda x: x.split()) \\\n",
    ".map(lambda x: (x,1)) \\\n",
    ".reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "words.cache()\n",
    "\n",
    "words.count() # triggers computation\n",
    "\n",
    "# 33505\n",
    "\n",
    "\n",
    "\n",
    "# [(u'fawn', 12), (u'mustachio', 1), (u'Debts', 1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"MIDSUMMER-NIGHT'S\", 1), ('Now', 741), ('Hippolyta', 6)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.take(3) # no computation required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33505"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count() # no computation required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33505"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#persist RDD\n",
    "doc = sc.textFile(\"shakespeare.txt\")\n",
    "\n",
    "words = doc.flatMap(lambda x: x.split()) \\\n",
    ".map(lambda x: (x,1)) \\\n",
    ".reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "words.persist()\n",
    "\n",
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"MIDSUMMER-NIGHT'S\", 1), ('Now', 741), ('Hippolyta', 6)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'(2) PythonRDD[26] at RDD at PythonRDD.scala:53 [Memory Serialized 1x Replicated]\\n |       CachedPartitions: 2; MemorySize: 629.5 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\\n |  MapPartitionsRDD[25] at mapPartitions at PythonRDD.scala:133 [Memory Serialized 1x Replicated]\\n |  ShuffledRDD[24] at partitionBy at NativeMethodAccessorImpl.java:0 [Memory Serialized 1x Replicated]\\n +-(2) PairwiseRDD[23] at reduceByKey at <ipython-input-16-91eaa4898d72>:6 [Memory Serialized 1x Replicated]\\n    |  PythonRDD[22] at reduceByKey at <ipython-input-16-91eaa4898d72>:6 [Memory Serialized 1x Replicated]\\n    |  shakespeare.txt MapPartitionsRDD[21] at textFile at NativeMethodAccessorImpl.java:0 [Memory Serialized 1x Replicated]\\n    |  shakespeare.txt HadoopRDD[20] at textFile at NativeMethodAccessorImpl.java:0 [Memory Serialized 1x Replicated]'\n"
     ]
    }
   ],
   "source": [
    "print(words.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33505"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checkpointing RDDs\n",
    "sc.setCheckpointDir('C:\\Spark_Examples\\Hour11\\checkpoint')\n",
    "\n",
    "doc = sc.textFile(\"shakespeare.txt\")\n",
    "\n",
    "words = doc.flatMap(lambda x: x.split()) \\\n",
    ".map(lambda x: (x,1)) \\\n",
    ".reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "words.checkpoint()\n",
    "\n",
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.isCheckpointed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:/C:/Spark_Examples/Hour11/checkpoint/6963451a-da3d-4432-86c6-fbedb663ee7b/rdd-35'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.getCheckpointFile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving RDD outputs\n",
    "doc = sc.textFile(\"shakespeare.txt\")\n",
    "\n",
    "words = doc.flatMap(lambda x: x.split())\n",
    "\n",
    "words.saveAsTextFile(\"gzip\",\"org.apache.hadoop.io.compress.GzipCodec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence files\n",
    "doc = sc.textFile(\"shakespeare.txt\")\n",
    "\n",
    "words = doc.flatMap(lambda x: x.split()) \\\n",
    ".keyBy(lambda x: x)\n",
    "\n",
    "words.saveAsSequenceFile(\"seqfiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hadoop Input and Output Formats\n",
    "#saveAsHadoopFile \n",
    "doc = sc.textFile(\"shakespeare.txt\")\n",
    "\n",
    "words = doc.flatMap(lambda x: x.split()) \\\n",
    ".map(lambda x: (x,1)) \\\n",
    ".reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "words.saveAsHadoopFile(\"hadoopcompseqfiles\",\n",
    "\n",
    "   outputFormatClass=\"org.apache.hadoop.mapred.SequenceFileOutputFormat\",\n",
    "\n",
    "   keyClass=\"org.apache.hadoop.io.Text\",\n",
    "\n",
    "   valueClass=\"org.apache.hadoop.io.IntWritable\",\n",
    "\n",
    "   keyConverter=None,\n",
    "\n",
    "   valueConverter=None,\n",
    "\n",
    "   conf=None,\n",
    "\n",
    "   compressionCodecClass=\"org.apache.hadoop.io.compress.SnappyCodec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveAsNewAPIHadoopFile \n",
    "cls = \"org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat\"\n",
    "\n",
    "doc = sc.textFile(\"shakespeare.txt\")\n",
    "\n",
    "words = doc.flatMap(lambda x: x.split()) \\\n",
    ".map(lambda x: (x,1)) \\\n",
    ".reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "words.saveAsNewAPIHadoopFile(\"newAPIfiles\",\n",
    "\n",
    "   outputFormatClass=cls,\n",
    "\n",
    "   keyClass=\"org.apache.hadoop.io.Text\",\n",
    "\n",
    "   valueClass=\"org.apache.hadoop.io.IntWritable\",\n",
    "\n",
    "   keyConverter=None,\n",
    "\n",
    "   valueConverter=None,\n",
    "\n",
    "   conf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
