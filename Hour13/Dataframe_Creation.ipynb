{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1='Jeff', _2=46), Row(_1='Kellie', _2=44)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe creation using RDD\n",
    "myrdd = sc.parallelize([('Jeff', 46),('Kellie', 44)])\n",
    "sqlContext.createDataFrame(myrdd).collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe creation using Hive context\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import HiveContext\n",
    "sqlcr=\"\"\"CREATE EXTERNAL TABLE stations_ex\\n(\\nstation_id INT,\\nname STRING,\\nlat DOUBLE,\\nlong DOUBLE,\\ndockcount INT,\\nlandmark STRING,\\ninstallation STRING\\n) \\nROW FORMAT DELIMITED \\nFIELDS TERMINATED BY ',' \\nSTORED AS TEXTFILE \\nLOCATION 'C:/Spark_Examples/Hour13/stations.csv;'\"\"\"\n",
    "sqlContext.sql(sqlcr)\n",
    "hiveContext = HiveContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----+\n",
      "|name|lat|long|\n",
      "+----+---+----+\n",
      "+----+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_cmd = \"\"\"SELECT name, lat,long FROM stations_ex\"\"\"\n",
    "sqlContext.sql(sql_cmd).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----------+\n",
      "|database|    tableName|isTemporary|\n",
      "+--------+-------------+-----------+\n",
      "| default|     stations|      false|\n",
      "| default| stations_csv|      false|\n",
      "| default|stations_hive|      false|\n",
      "| default|stations_list|      false|\n",
      "| default| stations_qqq|      false|\n",
      "| default|stations_test|      false|\n",
      "+--------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"load data local inpath 'stations.csv' overwrite into table stations_hive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----------+----------+--------------------+---------+-----------+---------+------------+------------+\n",
      "|                name|      lat|       long|station_id|                name|      lat|       long|dockcount|    landmark|installation|\n",
      "+--------------------+---------+-----------+----------+--------------------+---------+-----------+---------+------------+------------+\n",
      "|                name|     null|       null|      null|                name|     null|       null|     null|    landmark|        date|\n",
      "|San Jose Diridon ...|37.329732|-121.901782|         2|San Jose Diridon ...|37.329732|-121.901782|       27|    San Jose|    8/6/2013|\n",
      "|San Jose Civic Ce...|37.330698|-121.888979|         3|San Jose Civic Ce...|37.330698|-121.888979|       15|    San Jose|    8/5/2013|\n",
      "|Santa Clara at Al...|37.333988|-121.894902|         4|Santa Clara at Al...|37.333988|-121.894902|       11|    San Jose|    8/6/2013|\n",
      "|    Adobe on Almaden|37.331415|  -121.8932|         5|    Adobe on Almaden|37.331415|  -121.8932|       19|    San Jose|    8/5/2013|\n",
      "|    San Pedro Square|37.336721|-121.894074|         6|    San Pedro Square|37.336721|-121.894074|       15|    San Jose|    8/7/2013|\n",
      "|Paseo de San Antonio|37.333798|-121.886943|         7|Paseo de San Antonio|37.333798|-121.886943|       15|    San Jose|    8/7/2013|\n",
      "| San Salvador at 1st|37.330165|-121.885831|         8| San Salvador at 1st|37.330165|-121.885831|       15|    San Jose|    8/5/2013|\n",
      "|           Japantown|37.348742|-121.894715|         9|           Japantown|37.348742|-121.894715|       15|    San Jose|    8/5/2013|\n",
      "|  San Jose City Hall|37.337391|-121.886995|        10|  San Jose City Hall|37.337391|-121.886995|       15|    San Jose|    8/6/2013|\n",
      "|         MLK Library|37.335885| -121.88566|        11|         MLK Library|37.335885| -121.88566|       19|    San Jose|    8/6/2013|\n",
      "|SJSU 4th at San C...|37.332808|-121.883891|        12|SJSU 4th at San C...|37.332808|-121.883891|       19|    San Jose|    8/7/2013|\n",
      "|       St James Park|37.339301|-121.889937|        13|       St James Park|37.339301|-121.889937|       15|    San Jose|    8/6/2013|\n",
      "|Arena Green / SAP...|37.332692|-121.900084|        14|Arena Green / SAP...|37.332692|-121.900084|       19|    San Jose|    8/5/2013|\n",
      "|SJSU - San Salvad...|37.333955|-121.877349|        16|SJSU - San Salvad...|37.333955|-121.877349|       15|    San Jose|    8/7/2013|\n",
      "|   Franklin at Maple|37.481758|-122.226904|        21|   Franklin at Maple|37.481758|-122.226904|       15|Redwood City|   8/12/2013|\n",
      "|Redwood City Calt...|37.486078|-122.232089|        22|Redwood City Calt...|37.486078|-122.232089|       25|Redwood City|   8/15/2013|\n",
      "|San Mateo County ...|37.487616|-122.229951|        23|San Mateo County ...|37.487616|-122.229951|       15|Redwood City|   8/15/2013|\n",
      "|Redwood City Publ...|37.484219|-122.227424|        24|Redwood City Publ...|37.484219|-122.227424|       15|Redwood City|   8/12/2013|\n",
      "|Stanford in Redwo...| 37.48537|-122.203288|        25|Stanford in Redwo...| 37.48537|-122.203288|       15|Redwood City|   8/12/2013|\n",
      "+--------------------+---------+-----------+----------+--------------------+---------+-----------+---------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_cmd = \"\"\"SELECT name, lat,long,* FROM stations_hive\"\"\"\n",
    "sqlContext.sql(sql_cmd).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----------+\n",
      "|                name|      lat|       long|\n",
      "+--------------------+---------+-----------+\n",
      "|San Jose Diridon ...|37.329732|-121.901782|\n",
      "|San Jose Civic Ce...|37.330698|-121.888979|\n",
      "|Santa Clara at Al...|37.333988|-121.894902|\n",
      "|    Adobe on Almaden|37.331415|  -121.8932|\n",
      "|    San Pedro Square|37.336721|-121.894074|\n",
      "|Paseo de San Antonio|37.333798|-121.886943|\n",
      "| San Salvador at 1st|37.330165|-121.885831|\n",
      "|           Japantown|37.348742|-121.894715|\n",
      "|  San Jose City Hall|37.337391|-121.886995|\n",
      "|         MLK Library|37.335885| -121.88566|\n",
      "|SJSU 4th at San C...|37.332808|-121.883891|\n",
      "|       St James Park|37.339301|-121.889937|\n",
      "|Arena Green / SAP...|37.332692|-121.900084|\n",
      "|SJSU - San Salvad...|37.333955|-121.877349|\n",
      "|Santa Clara Count...|37.352601|-121.905733|\n",
      "|         Ryland Park|37.342725|-121.895617|\n",
      "+--------------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_cmd = \"\"\"SELECT name, lat,long FROM stations where landmark='San Jose'\"\"\"\n",
    "sqlContext.sql(sql_cmd).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------+\n",
      "|      lat|     long|            name|\n",
      "+---------+---------+----------------+\n",
      "|37.331415|-121.8932|Adobe on Almaden|\n",
      "+---------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DataFrames creation by json file\n",
    "df = sqlContext.read.json('stations.json')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------------+\n",
      "|      lat|       long|            name|\n",
      "+---------+-----------+----------------+\n",
      "|37.331415|  -121.8932|Adobe on Almaden|\n",
      "|37.348742|-121.894715|       Japantown|\n",
      "+---------+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dataframes from JSON RDD\n",
    "stationsrdd = sc.parallelize(['{\"name\":\"Adobe on Almaden\", \"lat\":37.331415, \"long\":-121.8932}','{\"name\":\"Japantown\", \"lat\":37.348742, \"long\":-121.894715}'])\n",
    "df = sqlContext.read.json(stationsrdd)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|slno,name,lat,lon...|\n",
      "|2,San Jose Dirido...|\n",
      "|3,San Jose Civic ...|\n",
      "|4,Santa Clara at ...|\n",
      "|5,Adobe on Almade...|\n",
      "|6,San Pedro Squar...|\n",
      "|7,Paseo de San An...|\n",
      "|8,San Salvador at...|\n",
      "|9,Japantown,37.34...|\n",
      "|10,San Jose City ...|\n",
      "|11,MLK Library,37...|\n",
      "|12,SJSU 4th at Sa...|\n",
      "|13,St James Park,...|\n",
      "|14,Arena Green / ...|\n",
      "|16,SJSU - San Sal...|\n",
      "|21,Franklin at Ma...|\n",
      "|22,Redwood City C...|\n",
      "|23,San Mateo Coun...|\n",
      "|24,Redwood City P...|\n",
      "|25,Stanford in Re...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read individual file\n",
    "df = sqlContext.read.text('stations.csv')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+---------+-----------+-----+------------+---------+\n",
      "|slno|                name|      lat|       long|value|    landmark|     date|\n",
      "+----+--------------------+---------+-----------+-----+------------+---------+\n",
      "|   2|San Jose Diridon ...|37.329732|-121.901782|   27|    San Jose| 8/6/2013|\n",
      "|   3|San Jose Civic Ce...|37.330698|-121.888979|   15|    San Jose| 8/5/2013|\n",
      "|   4|Santa Clara at Al...|37.333988|-121.894902|   11|    San Jose| 8/6/2013|\n",
      "|   5|    Adobe on Almaden|37.331415|  -121.8932|   19|    San Jose| 8/5/2013|\n",
      "|   6|    San Pedro Square|37.336721|-121.894074|   15|    San Jose| 8/7/2013|\n",
      "|   7|Paseo de San Antonio|37.333798|-121.886943|   15|    San Jose| 8/7/2013|\n",
      "|   8| San Salvador at 1st|37.330165|-121.885831|   15|    San Jose| 8/5/2013|\n",
      "|   9|           Japantown|37.348742|-121.894715|   15|    San Jose| 8/5/2013|\n",
      "|  10|  San Jose City Hall|37.337391|-121.886995|   15|    San Jose| 8/6/2013|\n",
      "|  11|         MLK Library|37.335885| -121.88566|   19|    San Jose| 8/6/2013|\n",
      "|  12|SJSU 4th at San C...|37.332808|-121.883891|   19|    San Jose| 8/7/2013|\n",
      "|  13|       St James Park|37.339301|-121.889937|   15|    San Jose| 8/6/2013|\n",
      "|  14|Arena Green / SAP...|37.332692|-121.900084|   19|    San Jose| 8/5/2013|\n",
      "|  16|SJSU - San Salvad...|37.333955|-121.877349|   15|    San Jose| 8/7/2013|\n",
      "|  21|   Franklin at Maple|37.481758|-122.226904|   15|Redwood City|8/12/2013|\n",
      "|  22|Redwood City Calt...|37.486078|-122.232089|   25|Redwood City|8/15/2013|\n",
      "|  23|San Mateo County ...|37.487616|-122.229951|   15|Redwood City|8/15/2013|\n",
      "|  24|Redwood City Publ...|37.484219|-122.227424|   15|Redwood City|8/12/2013|\n",
      "|  25|Stanford in Redwo...| 37.48537|-122.203288|   15|Redwood City|8/12/2013|\n",
      "|  26|Redwood City Medi...|37.487682|-122.223492|   15|Redwood City|8/12/2013|\n",
      "+----+--------------------+---------+-----------+-----+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv('stations.csv',header='true')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"stations_hive.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- slno: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf = sqlContext.read.parquet('stations.parquet')\n",
    "newdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+---------+-----------+-----+------------+---------+\n",
      "|slno|                name|      lat|       long|value|    landmark|     date|\n",
      "+----+--------------------+---------+-----------+-----+------------+---------+\n",
      "|   2|San Jose Diridon ...|37.329732|-121.901782|   27|    San Jose| 8/6/2013|\n",
      "|   3|San Jose Civic Ce...|37.330698|-121.888979|   15|    San Jose| 8/5/2013|\n",
      "|   4|Santa Clara at Al...|37.333988|-121.894902|   11|    San Jose| 8/6/2013|\n",
      "|   5|    Adobe on Almaden|37.331415|  -121.8932|   19|    San Jose| 8/5/2013|\n",
      "|   6|    San Pedro Square|37.336721|-121.894074|   15|    San Jose| 8/7/2013|\n",
      "|   7|Paseo de San Antonio|37.333798|-121.886943|   15|    San Jose| 8/7/2013|\n",
      "|   8| San Salvador at 1st|37.330165|-121.885831|   15|    San Jose| 8/5/2013|\n",
      "|   9|           Japantown|37.348742|-121.894715|   15|    San Jose| 8/5/2013|\n",
      "|  10|  San Jose City Hall|37.337391|-121.886995|   15|    San Jose| 8/6/2013|\n",
      "|  11|         MLK Library|37.335885| -121.88566|   19|    San Jose| 8/6/2013|\n",
      "|  12|SJSU 4th at San C...|37.332808|-121.883891|   19|    San Jose| 8/7/2013|\n",
      "|  13|       St James Park|37.339301|-121.889937|   15|    San Jose| 8/6/2013|\n",
      "|  14|Arena Green / SAP...|37.332692|-121.900084|   19|    San Jose| 8/5/2013|\n",
      "|  16|SJSU - San Salvad...|37.333955|-121.877349|   15|    San Jose| 8/7/2013|\n",
      "|  21|   Franklin at Maple|37.481758|-122.226904|   15|Redwood City|8/12/2013|\n",
      "|  22|Redwood City Calt...|37.486078|-122.232089|   25|Redwood City|8/15/2013|\n",
      "|  23|San Mateo County ...|37.487616|-122.229951|   15|Redwood City|8/15/2013|\n",
      "|  24|Redwood City Publ...|37.484219|-122.227424|   15|Redwood City|8/12/2013|\n",
      "|  25|Stanford in Redwo...| 37.48537|-122.203288|   15|Redwood City|8/12/2013|\n",
      "|  26|Redwood City Medi...|37.487682|-122.223492|   15|Redwood City|8/12/2013|\n",
      "+----+--------------------+---------+-----------+-----+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----------+\n",
      "|         name|      lat|       long|\n",
      "+-------------+---------+-----------+\n",
      "|St James Park|37.339301|-121.889937|\n",
      "+-------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.filter(newdf.name == 'St James Park') \\\n",
    ".select(newdf.name,newdf.lat,newdf.long) \\\n",
    ".show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|    _1| _2|\n",
      "+------+---+\n",
      "|  Jeff| 46|\n",
      "|Kellie| 44|\n",
      "|  Jeff| 46|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Distinct function\n",
    "rdd = sc.parallelize([('Jeff', 46),('Kellie', 44),('Jeff', 46)])\n",
    "df = sqlContext.createDataFrame(rdd)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|    _1| _2|\n",
      "+------+---+\n",
      "|  Jeff| 46|\n",
      "|Kellie| 44|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['San Jose Diridon Caltrain Station',\n",
       " 'San Jose Civic Center',\n",
       " 'Santa Clara at Almaden',\n",
       " 'Adobe on Almaden',\n",
       " 'San Pedro Square',\n",
       " 'Paseo de San Antonio',\n",
       " 'San Salvador at 1st',\n",
       " 'Japantown',\n",
       " 'San Jose City Hall',\n",
       " 'MLK Library',\n",
       " 'SJSU 4th at San Carlos',\n",
       " 'St James Park',\n",
       " 'Arena Green / SAP Center',\n",
       " 'SJSU - San Salvador at 9th',\n",
       " 'Franklin at Maple',\n",
       " 'Redwood City Caltrain Station',\n",
       " 'San Mateo County Center',\n",
       " 'Redwood City Public Library',\n",
       " 'Stanford in Redwood City',\n",
       " 'Redwood City Medical Center']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select, map, and flatMap\n",
    "df = sqlContext.read.parquet('stations.parquet')\n",
    "\n",
    "rdd = df.rdd.map(lambda r: r.name)\n",
    "\n",
    "rdd\n",
    "\n",
    "rdd.take(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        Station Name|\n",
      "+--------------------+\n",
      "|San Jose Diridon ...|\n",
      "|San Jose Civic Ce...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.parquet('stations.parquet')\n",
    "\n",
    "newdf = df.select((df.name).alias(\"Station Name\"))\n",
    "\n",
    "newdf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------+--------+\n",
      "|      lat|       long|fun_lat|fun_long|\n",
      "+---------+-----------+-------+--------+\n",
      "|37.329732|-121.901782|      N|       E|\n",
      "|37.330698|-121.888979|      N|       E|\n",
      "|37.333988|-121.894902|      N|       E|\n",
      "|37.331415|  -121.8932|      N|       E|\n",
      "|37.336721|-121.894074|      N|       E|\n",
      "|37.333798|-121.886943|      N|       E|\n",
      "|37.330165|-121.885831|      N|       E|\n",
      "|37.348742|-121.894715|      N|       E|\n",
      "|37.337391|-121.886995|      N|       E|\n",
      "|37.335885| -121.88566|      N|       E|\n",
      "|37.332808|-121.883891|      N|       E|\n",
      "|37.339301|-121.889937|      N|       E|\n",
      "|37.332692|-121.900084|      N|       E|\n",
      "|37.333955|-121.877349|      N|       E|\n",
      "|37.481758|-122.226904|      N|       E|\n",
      "|37.486078|-122.232089|      N|       E|\n",
      "|37.487616|-122.229951|      N|       E|\n",
      "|37.484219|-122.227424|      N|       E|\n",
      "| 37.48537|-122.203288|      N|       E|\n",
      "|37.487682|-122.223492|      N|       E|\n",
      "+---------+-----------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#User defined functions\n",
    "df = sqlContext.read.parquet('stations_hive.parquet')\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "lat2dir = udf(lambda x: 'N' if x !='0' else 'S', StringType())\n",
    "\n",
    "lon2dir = udf(lambda x: 'E' if x != '0' else 'W', StringType())\n",
    "\n",
    "(\n",
    "    df.select('lat',\n",
    "          'long', \n",
    "          lat2dir('lat').alias('fun_lat'),\n",
    "          lon2dir('long').alias('fun_long'))\n",
    "\n",
    ".show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(slno='2', name='San Jose Diridon Caltrain Station', lat='37.329732', long='-121.901782', value='27', landmark='San Jose', date='8/6/2013')]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: trips;'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o25.table.\n: org.apache.spark.sql.AnalysisException: Table or view not found: trips;\r\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:47)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:731)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:683)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:713)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:706)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:706)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:652)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\r\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\r\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:106)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\r\n\tat org.apache.spark.sql.SparkSession.table(SparkSession.scala:628)\r\n\tat org.apache.spark.sql.SparkSession.table(SparkSession.scala:624)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: Table or view 'trips' not found in database 'default';\r\n\tat org.apache.spark.sql.hive.client.HiveClient$$anonfun$getTable$1.apply(HiveClient.scala:81)\r\n\tat org.apache.spark.sql.hive.client.HiveClient$$anonfun$getTable$1.apply(HiveClient.scala:81)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.sql.hive.client.HiveClient$class.getTable(HiveClient.scala:81)\r\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.getTable(HiveClientImpl.scala:83)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.getRawTable(HiveExternalCatalog.scala:118)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$getTable$1.apply(HiveExternalCatalog.scala:700)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$getTable$1.apply(HiveExternalCatalog.scala:700)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.getTable(HiveExternalCatalog.scala:699)\r\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.getTable(ExternalCatalogWithListener.scala:138)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupRelation(SessionCatalog.scala:706)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:728)\r\n\t... 44 more\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-3049146230b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Joining dataframes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrips\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trips\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\context.py\u001b[0m in \u001b[0;36mtable\u001b[1;34m(self, tableName)\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \"\"\"\n\u001b[1;32m--> 371\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtableName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36mtable\u001b[1;34m(self, tableName)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \"\"\"\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtableName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: 'Table or view not found: trips;'"
     ]
    }
   ],
   "source": [
    "#Joining dataframes\n",
    "trips = sqlContext.table(\"trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
